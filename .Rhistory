#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.007)
tc=c(2)
ss=c(25)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset â™¥evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
th
eval
######################################################################
####################### Running the Model ############################
######################################################################
##now limit to important variables
butternut_list_variables <- c("PwetM", "MDR","MTDQ", "MTwetQ", "precip_season")
##now load variables for model running
butternut_sel_var <- butternut_var[,butternut_list_variables]
butternut_sel_df <- cbind(butternut_var[,1:3], butternut_sel_var)
butternut_sel_df[,3] <- as.numeric(butternut_sel_df[,3])
##now run models
par(mfrow=c(1,1))
set.seed(10)
butternut_samp <- sample(nrow(butternut_sel_df), round(0.70 * nrow(butternut_sel_df)))
testdata <- na.omit(butternut_sel_df[butternut_samp,])
traindata <- na.omit(butternut_sel_df[-butternut_samp,])
#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.07)
tc=c(2)
ss=c(25)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
######################################################################
####################### Running the Model ############################
######################################################################
##now limit to important variables
#butternut_list_variables <- c("PwetM", "MDR","MTDQ", "MTwetQ", "precip_season")
butternut_list_variables <- c("PwetM", "MDR","MTDQ", "MTwetQ")
##now load variables for model running
butternut_sel_var <- butternut_var[,butternut_list_variables]
butternut_sel_df <- cbind(butternut_var[,1:3], butternut_sel_var)
butternut_sel_df[,3] <- as.numeric(butternut_sel_df[,3])
##now run models
par(mfrow=c(1,1))
set.seed(10)
butternut_samp <- sample(nrow(butternut_sel_df), round(0.70 * nrow(butternut_sel_df)))
testdata <- na.omit(butternut_sel_df[butternut_samp,])
traindata <- na.omit(butternut_sel_df[-butternut_samp,])
#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.007)
tc=c(2)
ss=c(25)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
######################################################################
####################### Running the Model ############################
######################################################################
##now limit to important variables
#butternut_list_variables <- c("PwetM", "MDR","MTDQ", "MTwetQ", "precip_season")
butternut_list_variables <- c("PwetM", "MDR","MTDQ", "precip_season")
##now load variables for model running
butternut_sel_var <- butternut_var[,butternut_list_variables]
butternut_sel_df <- cbind(butternut_var[,1:3], butternut_sel_var)
butternut_sel_df[,3] <- as.numeric(butternut_sel_df[,3])
##now run models
par(mfrow=c(1,1))
set.seed(10)
butternut_samp <- sample(nrow(butternut_sel_df), round(0.70 * nrow(butternut_sel_df)))
testdata <- na.omit(butternut_sel_df[butternut_samp,])
traindata <- na.omit(butternut_sel_df[-butternut_samp,])
#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.007)
tc=c(2)
ss=c(25)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
th
######################################################################
####################### Running the Model ############################
######################################################################
##now limit to important variables
#butternut_list_variables <- c("PwetM", "MDR","MTDQ", "MTwetQ", "precip_season")
butternut_list_variables <- c("PwetM", "MDR","MTDQ", "MTwetQ", "precip_season")
##now load variables for model running
butternut_sel_var <- butternut_var[,butternut_list_variables]
butternut_sel_df <- cbind(butternut_var[,1:3], butternut_sel_var)
butternut_sel_df[,3] <- as.numeric(butternut_sel_df[,3])
##now run models
par(mfrow=c(1,1))
set.seed(10)
butternut_samp <- sample(nrow(butternut_sel_df), round(0.70 * nrow(butternut_sel_df)))
testdata <- na.omit(butternut_sel_df[butternut_samp,])
traindata <- na.omit(butternut_sel_df[-butternut_samp,])
#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.0007)
tc=c(2)
ss=c(25)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
th
source('~/GitHub/butternut/SDMs/5_SDMs_BRT_predictionmaps.R', echo=TRUE)
#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.007)
#Model calibration. Using multiple BRT parameters to identify the best number of trees. See the Elith tutorial on what these parameters mean.
###there's a bunch of other things but code line 384 is how you do the predictions and generate the map. Most of the other things in here
####are either in the Elith tutorial or were related to finding range contraction and
####expansion.
bf=c(.7)
lr=c(0.007)
tc=c(2)
ss=c(25)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
# pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
# d <- cbind(testdata$PA, pred_test)
# pres <- d[d[,1]==1, 2]
# abs <- d[d[,1]==0, 2]
# eval <- evaluate(p=pres, a=abs)
# ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
#th<-eval@t[which.max(eval@TPR+eval@TNR)]
#independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
df<-rbind(df, data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
df
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
?evaluate
evaluate(butternut_model,testdata,TSS)
eval <- evaluate(p=pres, a=abs, butternut_model)
detach("package:biomod2", unload = TRUE)
eval <- evaluate(p=pres, a=abs, butternut_model)
eval
ext.residual.deviance
butternut_model$gbm.call$best.trees
butternut_model_name
data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance)
#Initiate the loop to identify the best number of trees. Call your model whatever you want- the "gbm.x = 4:7" are the columns of your climate variables and the "gbm.y=3" is the column on your csv file that has 0's and 1's for presence/absence
for (i in 1:length(lr)){
for (j in 1:length(bf)){
for (k in 1:length(tc)){
for(l in 1:length(ss)){
##Fit the gbm model
#create a model name to store in the results table, I removed for (l in 1:length(ss)), ss[l],{ dist[t],'_'and
butternut_model_name <- paste('butternut_model_',tc[k],'_',lr[i],'_',bf[j],'_',ss[l],'_',sep='')
set.seed(10)
butternut_model <- gbm.step(traindata, gbm.x = 4:length(butternut_sel_df), gbm.y = 3, family = "bernoulli", step.size = ss[l],tree.complexity = tc[k],learning.rate = lr[i], bag.fraction = bf[j])
#Model internal metrics
cv.AUC = butternut_model$cv.statistics$discrimination.mean
cv.dev = butternut_model$cv.statistics$deviance.mean # average residual deviance over all folds during cross-validation
#Calculate the % of deviance explained. Deviance explained corresponds to the percentage of deviance for the null model explained by the fitted model (dev = 100% for a perfect model)
#The function calc.deviance() in dismo package calculates the deviance between 2 vectors v 1 and v 2
#calculating deviance explained by the model over the training dataset (int.dev)
int.null.deviance = butternut_model$self.statistics$mean.null
int.residual.deviance = butternut_model$cv.statistics$deviance.mean
int.dev=(int.null.deviance-int.residual.deviance)/int.null.deviance
pred.train = predict.gbm(butternut_model, traindata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
train=calc.deviance(traindata$PA, pred.train)
##Model external metrics , calculated over an evaluation dataset evaluation
pred_test = predict.gbm(butternut_model, testdata, n.trees = butternut_model$gbm.call$best.trees, type = "response")
d <- cbind(testdata$PA, pred_test)
pres <- d[d[,1]==1, 2]
abs <- d[d[,1]==0, 2]
eval <- evaluate(p=pres, a=abs)
ext.AUC <- eval@auc
#estimating the threshold to convert suitability values into binary maps (0/1)
th<-eval@t[which.max(eval@TPR+eval@TNR)]
#independent=calc.deviance(testdata$PA, pred_test)
#residual deviance was calculated between observed presence/absence data (v 1) and predicted probability of presence (v 2 ),
ext.residual.deviance = calc.deviance(testdata$PA, pred_test, calc.mean=T)
ext.null.deviance = calc.deviance(testdata$PA,rep(mean(testdata$PA),nrow(testdata)), calc.mean=T)
#Calculating deviance explained in the evaluation dataset. Portion of data withheld during model building
ext.dev=(ext.null.deviance - ext.residual.deviance)/ext.null.deviance
param_df <- rbind(data.frame(butternut_model_name,tc[k],lr[i],bf[j],ss[l],butternut_model$gbm.call$best.trees,cv.AUC,ext.AUC,int.dev,ext.dev,train,independent,ext.residual.deviance))
}
}
}
}
th
plot(hsm_list[[1]] > th)
plot(hsm_list[[2]] > th)
plot(hsm_list[[3]] > th)
##Load in presence and absence points
butternut_pres <- butternut_sel_df[butternut_sel_df$PA == 1,]
butternut_abs <- butternut_sel_df[butternut_sel_df$PA == 0,]
##create points
coordinates(butternut_pres) <- c('Longitude', 'Latitude')
proj4string(butternut_pres) <- CRS(projection)
coordinates(butternut_abs) <- c('Longitude', 'Latitude')
proj4string(butternut_abs) <- CRS(projection)
plot(butternut_prediction_map, main = "HSM Presence")
points(butternut_pres, col = "dodgerblue", pch = 16)
?extract
extract(butternut_prediction_map, butternut_pres)
butternut_pres_value <- extract(butternut_prediction_map, butternut_pres)
min(butternut_pres_value)
min(butternut_pres_value)*100
mean(butternut_pres_value)*100
QUHA_hyrbid <- read.csv("G:\\Shared drives\\Emily_Schumacher\\QUHA\\QUHA_hybrid")
QUHA_hyrbid <- read.csv("G:\\Shared drives\\Emily_Schumacher\\QUHA\\QUHA_hybrid.csv")
coordinates(QUHA_hyrbid) <- c('Longitude', 'Latitude')
QUHA_hyrbid
QUHA_hyrbid <- read.csv("G:\\Shared drives\\Emily_Schumacher\\QUHA\\QUHA_hybrid.csv")
coordinates(QUHA_hyrbid) <- c('Longitude', 'Latitude')
coordinates(QUHA_hyrbid) <- c('Longitude', 'Latitude')
proj4string(QUHA_hyrbid) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
QUHA_map <- getMap(resolution = "low")
library(rworldmap)
QUHA_map <- getMap(resolution = "low")
plot(QUHA_map)
points(QUHA_hyrbid)
min(QUHA_hyrbid)
QUHA_hyrbid <- read.csv("G:\\Shared drives\\Emily_Schumacher\\QUHA\\QUHA_hybrid.csv")
lon_min <- min(QUHA_hyrbid$Longitude)
lon_max <- max(QUHA_hyrbid$Longitude)
lat_min <- min(QUHA_hyrbid$Latitude)
lat_max <- max(QUHA_hyrbid$Latitude)
plot(QUHA_map, xlim = c(lon_min, lon_max), ylim = c(lat_min, lat_max))
QUHA_map <- getMap(resolution = "low", projection = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
QUHA_map <- getMap(resolution = "low")
?spTransform
QUHA_proj <- spTransform(QUHA_map, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
QUHA_proj <- spTransform(QUHA_map, "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
QUHA_proj <- spTransform(QUHA_map, crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
